{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reload the package when it is modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Multiagent Simulation    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "# set tf to cpu only\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "\n",
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "import mediapy\n",
    "from tqdm import tqdm\n",
    "import dataclasses\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import waymax\n",
    "from waymax import config as _config\n",
    "from waymax import dataloader\n",
    "from waymax import datatypes\n",
    "# from waymax import dynamics\n",
    "from waymax import env as _env\n",
    "from waymax import agents\n",
    "from waymax import visualization\n",
    "from rl_env.env_utils import inverse_unicycle_control, smooth_scenario\n",
    "from waymax.agents import actor_core\n",
    "from rl_env.waymax_env import MultiAgentEnvironment\n",
    "from rl_env.waymax_util import WomdLoader\n",
    "from rl_env.sim_agent_actor import SimAgentMTR\n",
    "from rl_env.unicycle_model import InvertibleUnicycleModel\n",
    "\n",
    "from mtr.config import cfg, cfg_from_yaml_file\n",
    "max_num_objects = 128\n",
    "\n",
    "# create a dataset\n",
    "WOMD_1_2_0_VAL_LOCAL = _config.DatasetConfig(\n",
    "    # path='/Data/Dataset/Waymo/V1_2_tf/validation_interactive/validation_interactive_tfexample.tfrecord@150',\n",
    "    path='/Data/Dataset/Waymo/V1_2_tf/validation/validation_tfexample.tfrecord@150',\n",
    "    # path='/Data/Dataset/Waymo/V1_2_tf/training/training_tfexample.tfrecord@1000',\n",
    "    max_num_rg_points=30000,\n",
    "    data_format=_config.DataFormat.TFRECORD,\n",
    "    max_num_objects=max_num_objects,\n",
    "    shuffle_seed = 99,\n",
    ")\n",
    "\n",
    "data_iter = WomdLoader(data_config=WOMD_1_2_0_VAL_LOCAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_id, scenario = data_iter.next()\n",
    "scenario: datatypes.SimulatorState = smooth_scenario(scenario)\n",
    "img = visualization.plot_simulator_state(scenario, use_log_traj=True, highlight_obj = _config.ObjectType.MODELED)\n",
    "mediapy.show_image(img)\n",
    "print(jnp.where(scenario.object_metadata.is_modeled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "from mtr.models.context_encoder.mtr_encoder import MTREncoder\n",
    "\n",
    "# from mtr.models.motion_decoder.bc_decoder import BCDecoder\n",
    "# dynamics_model = InvertibleUnicycleModel(max_accel=8, max_steering=0.8)\n",
    "# # 30k #755k\n",
    "# path = 'output/bc_bicycle_4_freeze/epoch=0-step=755000.ckpt'\n",
    "# cfg_path = 'tools/cfgs/waymo/bc_atten_ctrl.yaml'\n",
    "\n",
    "from mtr.models.motion_decoder.bc_decoder_discrete import BCDecoder\n",
    "dynamics_model = InvertibleUnicycleModel(max_accel=8, max_steering=0.8)\n",
    "path = 'output/bc_discrete_4_freeze/epoch=0-step=900000.ckpt'\n",
    "# path = 'output/bc_discrete_4_freeze/epoch=0-step=500000.ckpt'\n",
    "cfg_path = 'tools/cfgs/waymo/bc_atten_discrete.yaml'\n",
    "\n",
    "# from mtr.models.motion_decoder.bc_decoder_delta import BCDecoder\n",
    "# dynamics_model = waymax.dynamics.DeltaLocal()\n",
    "# path = 'output/bc_atten_4_unfreeze_state/epoch=19-step=1211340.ckpt'\n",
    "# cfg_path = 'tools/cfgs/waymo/rl_finetune.yaml'\n",
    "\n",
    "cfg = cfg_from_yaml_file(cfg_path, cfg)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config the multi-agent environment:\n",
    "init_steps = 11\n",
    "\n",
    "# Set the dynamics model the environment is using.\n",
    "# Note each actor interacting with the environment needs to provide action\n",
    "# compatible with this dynamics model.\n",
    "\n",
    "# Expect users to control all valid object in the scene.\n",
    "env = MultiAgentEnvironment(\n",
    "    dynamics_model=dynamics_model,\n",
    "    config=dataclasses.replace(\n",
    "        _config.EnvironmentConfig(),\n",
    "        init_steps = init_steps,\n",
    "        max_num_objects=max_num_objects,\n",
    "        controlled_object=_config.ObjectType.MODELED,\n",
    "        rewards = _config.LinearCombinationRewardConfig(\n",
    "            rewards={\n",
    "                'overlap': 1.0, # Positive is good.  \n",
    "                'offroad': 1.0, # Negative is good.\n",
    "                'kinematics': 1.0, # Negative is good.\n",
    "            }\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Control Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "def check_controlled(state: datatypes.SimulatorState):\n",
    "    # is_valid = jnp.logical_or(state.object_metadata.is_modeled, state.object_metadata.is_sdc)\n",
    "    is_valid = state.sim_trajectory.valid[..., state.timestep]\n",
    "    \n",
    "    # get velocity in the log\n",
    "    v_x_log = state.log_trajectory.vel_x[:,:11] # [num_agents, num_steps]\n",
    "    v_y_log = state.log_trajectory.vel_y[:,:11] # [num_agents, num_steps]\n",
    "    valid_log = state.log_trajectory.valid[:, :11]\n",
    "    v_x_log = jnp.where(valid_log, v_x_log, 0)\n",
    "    v_y_log = jnp.where(valid_log, v_y_log, 0)\n",
    "    v_log = jnp.linalg.norm(jnp.stack([v_x_log, v_y_log], axis=-1), axis=-1)\n",
    "    v_max = jnp.max(v_log, axis=-1)\n",
    "    is_moving = v_max > 0.1\n",
    "    \n",
    "    is_vehicle = (state.object_metadata.object_types == 1)\n",
    "    \n",
    "    return jnp.logical_and(is_valid, jnp.logical_and(is_moving, is_vehicle))\n",
    "\n",
    "# @jax.jit\n",
    "# def check_controlled(state: datatypes.SimulatorState):\n",
    "#     return state.object_metadata.is_sdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a few actors, see visualization below for how each actor behaves.\n",
    "# An actor that doesn't move, controlling all objects with index > 4\n",
    "encoder = MTREncoder(cfg.MODEL.CONTEXT_ENCODER)\n",
    "decoder = BCDecoder(encoder.num_out_channels, cfg.MODEL.MOTION_DECODER)\n",
    "# load model\n",
    "state_dict = torch.load(path)['state_dict']\n",
    "\n",
    "encoder.load_model(state_dict)\n",
    "decoder.load_model(state_dict)\n",
    "\n",
    "actor_policy = SimAgentMTR(\n",
    "    context_encoder= encoder,\n",
    "    motion_decoder= decoder,\n",
    "    is_controlled_func = check_controlled,\n",
    ")\n",
    "\n",
    "actor_policy.eval()\n",
    "actor_policy.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a scenario from the dataset\n",
    "# scenario : datatypes.SimulatorState = next(data_iter)\n",
    "n_agent = scenario.object_metadata.num_objects\n",
    "# a = np.zeros((n_agent, 91, 2))\n",
    "states = [env.reset(scenario)]\n",
    "for i in range(states[0].remaining_timesteps):\n",
    "  current_state = states[-1]\n",
    "  policy_output = actor_policy.select_action({}, current_state, None, None)\n",
    "  # a[:, i, :] = policy_output.action.data\n",
    "  next_state = env.step_sim_agent(states[-1], [policy_output])\n",
    "  states.append(next_state)\n",
    "\n",
    "idx =jnp.where(policy_output.is_controlled)[0]\n",
    "print(\"Sim Agent Ids:\", jnp.where(policy_output.is_controlled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for state in states:\n",
    "  imgs.append(visualization.plot_simulator_state(state, use_log_traj=False, highlight_obj = _config.ObjectType.MODELED))\n",
    "mediapy.show_video(imgs, fps=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waymax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
